# Embedding System Specification (Backlog)
**Version:** 1.0  
**Date:** October 7, 2025  
**Purpose:** Overview of vector embedding subsystem for future implementation  
**Status:** Backlog - Not Yet Prioritized

---

## Executive Summary

This document outlines a **future feature** for implementing a vector embedding system within Bright Run. The embedding system would generate, store, and manage vector representations of chunks for semantic search, similarity matching, and training data quality assessment.

**Current Status:** ❌ Not Implemented  
**Missing Dimensions:** 2 (`embedding_id`, `vector_checksum`)  
**Estimated Effort:** 16-40 hours  
**Priority:** Low (Backlog)

---

## What is Vector Embedding?

### Non-Technical Explanation
Vector embeddings are mathematical representations of text that capture its meaning. Think of it like this:

- Traditional search looks for exact word matches
- Embedding search understands meaning and context
- "How do I start?" and "Getting started guide" would be recognized as similar, even with different words

Each chunk of text gets converted into a list of numbers (a "vector") that represents its semantic meaning. Similar chunks have similar vectors.

### Technical Definition
Vector embeddings are dense numerical representations (typically 768-1536 dimensions) of text chunks, generated by neural language models. These vectors:
- Capture semantic similarity
- Enable cosine similarity matching
- Support efficient nearest-neighbor search
- Facilitate clustering and deduplication

---

## Benefits for Bright Run LoRA Platform

### 1. **Semantic Deduplication**
**Problem:** Users may upload documents with overlapping content  
**Solution:** Detect semantically similar chunks across documents  
**Benefit:** Prevent redundant training pairs, improve training efficiency

**How It Works:**
- Generate embeddings for all chunks
- Calculate similarity scores between chunks
- Flag duplicates or near-duplicates
- Let users decide whether to keep or merge similar content

**User Value:** "Your chunk on 'email marketing strategy' is 92% similar to one from your earlier playbook. Would you like to review?"

### 2. **Smart Training Pair Selection**
**Problem:** Not all chunks are equally valuable for training  
**Solution:** Use embedding similarity to select diverse, representative training pairs  
**Benefit:** Better model coverage with fewer training examples

**How It Works:**
- Cluster chunks by embedding similarity
- Ensure training set includes examples from all clusters
- Avoid over-representing common patterns
- Maximize semantic diversity

**User Value:** "We've selected 500 training pairs that cover 95% of your knowledge space (rather than 2,000 redundant pairs)."

### 3. **Content Gap Analysis**
**Problem:** Users don't know what knowledge is missing  
**Solution:** Visualize knowledge coverage using embedding space  
**Benefit:** Identify underrepresented topics

**How It Works:**
- Map all chunks in 2D/3D embedding space
- Identify sparse regions (gaps in coverage)
- Suggest areas for new content

**User Value:** "Your content covers marketing strategy well, but has limited examples on customer objection handling. Consider adding 3-5 more chunks in that area."

### 4. **Retrieval-Augmented Generation (RAG)**
**Problem:** Users want to query their knowledge base during testing  
**Solution:** Semantic search powered by embeddings  
**Benefit:** Find relevant chunks instantly, even with fuzzy queries

**How It Works:**
- User asks: "How do I handle price objections?"
- System converts query to embedding
- Finds top-K most similar chunks
- Returns relevant content

**User Value:** "Test your fine-tuned model by asking questions and seeing which training chunks it references."

### 5. **Training Data Quality Scoring**
**Problem:** Hard to assess if training data is high quality  
**Solution:** Use embedding-based metrics to detect issues  
**Benefit:** Improve training outcomes by filtering low-quality data

**How It Works:**
- Detect outlier chunks (very dissimilar from others)
- Identify overly generic chunks (too similar to common text)
- Flag potentially noisy or low-signal content

**User Value:** "This chunk appears to be generic boilerplate. Consider excluding it from training."

### 6. **Chunk Relationship Mapping**
**Problem:** Users lose track of how concepts connect  
**Solution:** Build knowledge graph using embedding similarity  
**Benefit:** Visualize relationships between ideas

**How It Works:**
- Calculate similarity between all chunks
- Create network graph where edges = similarity
- Visualize which topics are related

**User Value:** "Your 'pricing strategy' chunks are closely related to 'value proposition' chunks. Consider cross-referencing them."

### 7. **Style Consistency Detection**
**Problem:** Inconsistent writing style across documents  
**Solution:** Cluster chunks by stylistic similarity  
**Benefit:** Ensure brand voice consistency in training data

**How It Works:**
- Embeddings capture both content AND style
- Identify chunks with unusual tone/voice
- Flag style inconsistencies

**User Value:** "These 5 chunks have a different writing style than your typical brand voice. Review for consistency."

---

## Architecture Overview

### System Components

```
┌─────────────────────────────────────────────────────────┐
│                    Embedding System                     │
└─────────────────────────────────────────────────────────┘
                            │
        ┌───────────────────┼───────────────────┐
        │                   │                   │
        ▼                   ▼                   ▼
┌──────────────┐   ┌──────────────┐   ┌──────────────┐
│  Embedding   │   │   Vector     │   │   Search     │
│  Generation  │   │   Storage    │   │   Service    │
└──────────────┘   └──────────────┘   └──────────────┘
        │                   │                   │
        ▼                   ▼                   ▼
┌──────────────────────────────────────────────────────┐
│              chunk_embeddings Table                  │
│  - embedding_id (UUID)                               │
│  - chunk_id (FK)                                     │
│  - vector (pgvector)                                 │
│  - model_name (text)                                 │
│  - vector_checksum (text)                            │
│  - created_at (timestamp)                            │
└──────────────────────────────────────────────────────┘
```

### 1. Embedding Generation Service
**Purpose:** Convert chunk text to vector embeddings

**File Location:** `src/lib/embedding-service.ts` (to be created)

**Responsibilities:**
- Call embedding API (OpenAI, Voyage AI, etc.)
- Batch chunks for efficient processing
- Handle rate limiting and retries
- Calculate checksums for cache validation
- Generate unique embedding IDs

**API Options:**
- **OpenAI** `text-embedding-3-small` (1536 dimensions, $0.02/1M tokens)
- **OpenAI** `text-embedding-3-large` (3072 dimensions, $0.13/1M tokens)
- **Voyage AI** `voyage-2` (1024 dimensions, optimized for retrieval)
- **Cohere** `embed-english-v3.0` (1024 dimensions, multilingual)

### 2. Vector Storage
**Purpose:** Store and index embeddings for fast retrieval

**Technology:** Supabase pgvector extension

**Schema:**
```sql
-- Enable pgvector extension
CREATE EXTENSION IF NOT EXISTS vector;

-- Create embeddings table
CREATE TABLE chunk_embeddings (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  embedding_id TEXT UNIQUE NOT NULL,
  chunk_id UUID REFERENCES chunks(id) ON DELETE CASCADE,
  vector VECTOR(1536),  -- Dimension depends on model
  model_name TEXT NOT NULL,  -- e.g., 'text-embedding-3-small'
  model_version TEXT,  -- e.g., '2024-09'
  vector_checksum TEXT NOT NULL,  -- SHA-256 of chunk_text
  created_at TIMESTAMPTZ DEFAULT NOW(),
  
  -- Indexes
  CONSTRAINT unique_chunk_model UNIQUE(chunk_id, model_name)
);

-- Create vector similarity index (HNSW for fast search)
CREATE INDEX ON chunk_embeddings 
  USING hnsw (vector vector_cosine_ops);

-- Create regular indexes
CREATE INDEX idx_embeddings_chunk_id ON chunk_embeddings(chunk_id);
CREATE INDEX idx_embeddings_model ON chunk_embeddings(model_name);
```

### 3. Search Service
**Purpose:** Find similar chunks using vector similarity

**File Location:** `src/lib/search-service.ts` (to be created)

**Capabilities:**
- Semantic search by query text
- Find similar chunks (K-nearest neighbors)
- Similarity threshold filtering
- Multi-vector queries (find chunks similar to multiple examples)

**Query Types:**
```typescript
// 1. Text query → find similar chunks
searchByText(query: string, limit: number): Promise<Chunk[]>

// 2. Chunk → find similar chunks
findSimilarChunks(chunkId: string, limit: number): Promise<Chunk[]>

// 3. Vector → find similar chunks (for custom use cases)
searchByVector(vector: number[], limit: number): Promise<Chunk[]>
```

---

## Integration with Dimension Generation

### How Embeddings Fit in the Workflow

```
Document Upload
    ↓
Chunk Extraction
    ↓
Dimension Generation ← (Current focus)
    ↓
[NEW] Embedding Generation ← (This feature)
    ↓
Training Pair Generation
```

### Dimension Fields Populated

**1. embedding_id** (string)
- **Purpose:** Unique identifier for the stored embedding
- **Format:** UUID or hash (e.g., `embed_3f9ac2` or UUID)
- **Stored in:** `chunk_dimensions` table
- **References:** `chunk_embeddings.embedding_id`

**2. vector_checksum** (string)
- **Purpose:** SHA-256 hash of the chunk text that was embedded
- **Format:** `sha256:7b9a4f3e...` (64 hex chars)
- **Use Case:** Detect when chunk text changes and embedding needs regeneration
- **Stored in:** Both `chunk_dimensions` and `chunk_embeddings` tables

### Example Values
```json
{
  "embedding_id": "emb_a1b2c3d4-e5f6-4789-abcd-ef0123456789",
  "vector_checksum": "sha256:7b9a4f3e2c1d8f6e5a4b3c2d1e0f9a8b7c6d5e4f3a2b1c0d9e8f7a6b5c4d3e2f"
}
```

---

## Implementation Plan (When Prioritized)

### Phase 1: Foundation (Week 1)
**Effort:** 8 hours

1. **Database Setup**
   - Enable pgvector extension in Supabase
   - Create `chunk_embeddings` table
   - Create indexes for performance
   - Test with sample vectors

2. **Embedding Service Skeleton**
   - Create `src/lib/embedding-service.ts`
   - Implement API client (OpenAI or Voyage)
   - Add batch processing logic
   - Add checksum generation

### Phase 2: Core Generation (Week 1-2)
**Effort:** 12 hours

3. **Embedding Generation**
   - Integrate with chunk extraction workflow
   - Generate embeddings for new chunks
   - Store embeddings in database
   - Populate `embedding_id` and `vector_checksum` in dimensions

4. **Batch Processing**
   - Add queue for large document processing
   - Implement rate limiting
   - Add progress tracking
   - Handle errors gracefully

### Phase 3: Search & Retrieval (Week 2)
**Effort:** 8 hours

5. **Search Service**
   - Implement semantic search
   - Add similarity threshold filtering
   - Create search API endpoints
   - Build simple search UI

6. **Similar Chunks Feature**
   - Add "Find Similar" button to chunk view
   - Display similar chunks with similarity scores
   - Enable navigation between related chunks

### Phase 4: Advanced Features (Week 3-4)
**Effort:** 12 hours

7. **Deduplication**
   - Batch similarity calculation
   - Identify duplicate/near-duplicate chunks
   - Create deduplication report UI
   - Allow bulk merge/delete

8. **Knowledge Visualization**
   - 2D embedding projection (t-SNE or UMAP)
   - Interactive knowledge map
   - Cluster identification
   - Gap analysis

### Phase 5: Training Integration (Week 4)
**Effort:** 8 hours

9. **Diversity Selection**
   - Use embeddings to select diverse training pairs
   - Ensure cluster coverage
   - Optimize for semantic diversity
   - Add to training pair generation

10. **Quality Scoring**
    - Outlier detection
    - Genericity scoring
    - Style consistency checks
    - Quality report generation

---

## Cost Estimation

### API Costs (OpenAI text-embedding-3-small)
- **Price:** $0.02 per 1M tokens
- **Average chunk:** ~500 tokens
- **Cost per chunk:** ~$0.00001 (1/100th of a penny)
- **For 10,000 chunks:** ~$0.10

### Storage Costs (Supabase)
- **Vector size:** 1536 dimensions × 4 bytes = 6KB per embedding
- **For 10,000 chunks:** ~60 MB
- **Supabase storage:** Negligible (included in plan)

### Conclusion: Extremely affordable at scale

---

## Technical Dependencies

### External Services
1. **Embedding API** (choose one):
   - OpenAI API (recommended for MVP)
   - Voyage AI (optimized for retrieval)
   - Cohere (multilingual support)

2. **Vector Database:**
   - Supabase pgvector (already available)
   - No additional service needed

### Code Dependencies
1. **pgvector extension** in Supabase
2. **Embedding API client** (e.g., `openai` npm package)
3. **Vector math utilities** (cosine similarity, normalization)
4. **Checksum library** (crypto.createHash for SHA-256)

---

## Performance Considerations

### Bottlenecks
1. **API Rate Limits:**
   - OpenAI: 3,000 requests/min (Tier 2)
   - Solution: Batch processing, queue system

2. **Vector Index Size:**
   - HNSW index memory usage
   - Solution: Tune index parameters, periodic rebuilds

3. **Query Latency:**
   - Large vector searches can be slow
   - Solution: Use HNSW index, limit result set, cache common queries

### Optimization Strategies
- **Batch API calls** (up to 100 chunks per request)
- **Cache embeddings** (only regenerate if chunk text changes via checksum)
- **Use smaller models** for speed (768 vs 1536 dimensions)
- **Index tuning** (HNSW m and ef_construction parameters)

---

## Why This is Backlog (Not Immediate Priority)

### Current Focus
The immediate priority is getting **all 60 dimensions populated** for the core MVP functionality. The embedding system, while valuable, is not blocking any critical features.

### Dependencies
The embedding system depends on:
1. ✅ Chunk extraction working (done)
2. ✅ Dimension generation working (in progress)
3. ❌ Clear use case prioritization (TBD)
4. ❌ User feedback on which benefits are most valuable (TBD)

### Decision Criteria for Moving to Active
Prioritize embedding system when:
- [ ] All core dimensions working
- [ ] Users request semantic search
- [ ] Need deduplication for large document sets
- [ ] Training data quality becomes an issue
- [ ] Have 1-2 weeks for feature development

---

## Related Documents
- Original analysis: `pmc/context-ai/pmct/c-alpha-build-spec_v3.3_missing-dimensions_v1.md` (Section 2)
- Driver document: `pmc/context-ai/pmct/c-alpha-build-spec_v3.3_dimensions-driver_v1.md`
- Dimension metadata: `src/lib/dimension-metadata.ts` (lines 671-693 define embedding fields)

---

## Questions for Future Discussion

1. **Which embedding model?** OpenAI vs Voyage vs Cohere
2. **When to generate?** Immediately after chunks or in background job?
3. **Which benefits first?** Semantic search vs deduplication vs diversity selection
4. **UI/UX priorities?** Knowledge map vs similar chunks vs search interface
5. **Integration points?** Where in workflow should embeddings be visible?

---

**End of Embedding System Specification**

