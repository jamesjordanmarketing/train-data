# Chunks Alpha Build Spec v3.2 - Comprehensive Audit Report

**Date:** October 5, 2025  
**Specification:** `c-alpha-build-spec_v3.2.md` (2,610 lines)  
**Audit Purpose:** Evaluate completeness and coding agent readiness  
**Focus:** Identify critical knowledge outside build prompts that agents need

---

## EXECUTIVE SUMMARY

### Critical Finding: Information Architecture Problem

The specification contains **288 lines of critical UI/UX design information** (lines 59-346) that exist OUTSIDE the 5 build prompts. Build Prompt #4 references this section but does not contain the information inline, creating a **high-risk dependency** for coding agents receiving prompts individually.

### Audit Scope
- ‚úÖ Analyzed all 5 build prompts (lines 783-2562)
- ‚úÖ Catalogued external reference sections
- ‚úÖ Evaluated self-sufficiency of each prompt
- ‚úÖ Identified critical vs. nice-to-have information
- ‚úÖ Assessed risk levels for each dependency

### Risk Assessment

| Section | Lines | Content | Risk Level | Impact if Missing |
|---------|-------|---------|------------|-------------------|
| **Dashboard Design Reference** | 59-346 | UI patterns, color schemes, component structure | **üî¥ CRITICAL** | UI will not match design, wrong patterns implemented |
| **Executive Summary** | 28-56 | Architecture decisions, integration strategy | **üü° MODERATE** | May make suboptimal architectural choices |
| **Prerequisites & Human Setup** | 348-780 | SQL schema, API config, dependencies | **üü¢ LOW** | Human completes before AI, minimal impact |
| **Appendices** | 2567-2607 | Cost estimates, performance targets | **üü¢ LOW** | Nice-to-have context, not blocking |

### Recommended Solution

**Option D (Hybrid Approach)** with the following implementation:
1. **Embed critical design snippets** directly into Build Prompt #4 (add ~150 lines)
2. **Add architecture context primer** to Build Prompt #1 (add ~30 lines)
3. **Keep full spec available** as reference for the coding agent
4. **Create explicit cross-references** in prompts with line numbers

**Estimated Effort:** 2-3 hours to restructure and validate

---

## SECTION-BY-SECTION ANALYSIS

### Section 1: DASHBOARD WIREFRAME DESIGN REFERENCE (Lines 59-346)

**Content Summary:**
- Visual screenshot reference (lines 70-87)
- Complete UI component structure from `DocumentChunksOverview.tsx` (lines 89-301)
- Color coding system for chunk types (lines 200-225)
- Three-section card layout specification (lines 124-198)
- Icon mapping from lucide-react (lines 285-301)
- Design principles to follow (lines 303-327)
- Vite to Next.js adaptation notes (lines 339-346)

**Who Needs This:**
- Build Prompt #4 (Chunk Dashboard & Spreadsheet Interface)

**Current References in Build Prompts:**
```
Line 2103: "CRITICAL: This prompt REQUIRES you to follow the Dashboard Wireframe Design Reference section above."
Line 2106: "VISUAL TARGET: Refer to Figure 1 in the Dashboard Wireframe Design Reference section above"
```

**Risk Analysis:**
- **üî¥ CRITICAL RISK:** Build Prompt #4 cannot be executed successfully without this information
- **Impact:** Coding agent will either fail, ask for clarification, or implement incorrect UI patterns
- **Likelihood:** 100% - The prompt explicitly states this information is required

**Specific Dependencies:**

1. **Three-Section Card Layout** (lines 124-198)
   - Required for: Every chunk card in the dashboard
   - Contains: Exact structure, CSS classes, component hierarchy
   - Without it: Agent won't know about the Metadata ‚Üí Things We Know ‚Üí Things We Need to Know pattern

2. **Color Coding System** (lines 200-225)
   - Required for: Chunk type differentiation, confidence indicators
   - Contains: Exact color mappings (blue-200, purple-200, etc.)
   - Without it: Agent will invent arbitrary colors

3. **Icon Mappings** (lines 285-301)
   - Required for: Visual consistency throughout UI
   - Contains: Specific icon imports from lucide-react
   - Without it: Agent may use wrong icons or none at all

4. **Design Principles** (lines 303-327)
   - Required for: Understanding progressive disclosure, visual hierarchy
   - Contains: Key UX patterns like "3 items shown ‚Üí Detail View button"
   - Without it: Agent may show all data at once, breaking the design

**Recommendation:** MUST BE INTEGRATED INTO BUILD PROMPT #4

---

### Section 2: EXECUTIVE SUMMARY (Lines 28-56)

**Content Summary:**
- Module purpose (lines 35-41)
- Build strategy overview (lines 43-48)
- Key architectural decisions (lines 50-56)

**Who Needs This:**
- Build Prompt #1 (provides foundation context)
- Build Prompt #2 (understands extraction limits)
- Build Prompt #3 (understands AI model choice)

**Current References in Build Prompts:**
- None explicit

**Risk Analysis:**
- **üü° MODERATE RISK:** Architectural decisions inform implementation choices
- **Impact:** Agent may make inconsistent choices across prompts
- **Likelihood:** 30% - Agents can infer from prompt details, but explicit context is better

**Specific Architectural Decisions Missing from Prompts:**

1. **Integration Strategy** (line 51)
   ```
   "Integration: Build into existing chunks-alpha codebase"
   ```
   - Impact: Agent needs to know this is extending existing code, not greenfield
   - Current state: Build Prompt #1 mentions this but not prominently

2. **Processing Strategy** (line 52)
   ```
   "Processing: Batch processing with background jobs"
   ```
   - Impact: Informs how extraction and generation are structured
   - Current state: Prompts show code examples but don't explain the why

3. **UI Strategy** (line 55)
   ```
   "UI: Following existing dashboard wireframe design from chunks-alpha-dashboard"
   ```
   - Impact: Critical for Build Prompt #4
   - Current state: Mentioned but design details are external

**Recommendation:** ADD BRIEF CONTEXT PRIMER TO BUILD PROMPT #1

---

### Section 3: PREREQUISITES & HUMAN SETUP (Lines 348-780)

**Content Summary:**
- Database schema SQL (lines 354-719)
- API configuration (lines 735-767)
- Dependency installation (lines 772-779)

**Who Needs This:**
- Human operator (completes before AI prompts)

**Current References in Build Prompts:**
```
Line 786: "CONTEXT FOR AI: You are building the foundation... The database schema has been set up by the human"
```

**Risk Analysis:**
- **üü¢ LOW RISK:** This section is for human setup BEFORE AI prompts execute
- **Impact:** None - AI explicitly told "human has completed this"
- **Likelihood:** 0% - Process guarantees this is done first

**Recommendation:** NO CHANGES NEEDED - Proper separation of concerns

---

### Section 4: APPENDICES (Lines 2567-2607)

**Content Summary:**
- Appendix A: Data Dictionary Reference (lines 2568-2573)
- Appendix B: Prompt Engineering Guidelines (lines 2575-2581)
- Appendix C: Cost Estimation (lines 2583-2589)
- Appendix D: Performance Targets (lines 2591-2595)

**Who Needs This:**
- Optional context for all prompts

**Risk Analysis:**
- **üü¢ LOW RISK:** Nice-to-have information, not blocking
- **Impact:** Minor - May help with optimization decisions
- **Likelihood:** 5% - Prompts are sufficiently detailed without this

**Recommendation:** NO CHANGES NEEDED - Keep as reference material

---

## BUILD PROMPT INDIVIDUAL AUDITS

### BUILD PROMPT #1: Database Schema & Infrastructure (Lines 783-1196)

**Prompt Characteristics:**
- **Length:** 414 lines
- **Complexity:** Medium
- **External Dependencies:** Minimal

**Self-Sufficiency Analysis:**

‚úÖ **Strengths:**
- Complete TypeScript type definitions provided (lines 789-941)
- Full service implementations with code examples (lines 946-1156)
- Clear completion criteria (lines 1190-1195)
- Explicit instructions for each part (Parts A-E)

‚ö†Ô∏è **Weaknesses:**
1. **Missing Architecture Context** (line 786)
   - Says "You are building the foundation" but doesn't explain the overall module purpose
   - No mention of the 4 chunk types or why this module exists
   - Agent might not understand the bigger picture

2. **Implicit Assumptions** (lines 1169-1181)
   - Assumes knowledge of existing codebase structure
   - References `src/components/server/DocumentSelectorServer.tsx` without explaining its current state
   - No guidance on where "Chunks" button should be placed relative to existing buttons

**Recommended Changes:**

```markdown
Add to line 786 (before "CONTEXT FOR AI:"):

**MODULE CONTEXT:**
This is Phase 1 of building a chunk dimension testing environment that extends the existing 
document categorization module. The system will:
- Extract 4 chunk types (Chapter_Sequential, Instructional_Unit, CER, Example_Scenario)
- Generate 60+ AI dimensions per chunk using Claude Sonnet 4.5
- Display all data in spreadsheet interface for prompt testing

You are now building the database foundation for this system.

---
```

**Risk Level:** üü° MODERATE - Can execute but may lack strategic understanding

---

### BUILD PROMPT #2: Chunk Extraction Engine (Lines 1199-1759)

**Prompt Characteristics:**
- **Length:** 561 lines
- **Complexity:** High
- **External Dependencies:** Minimal

**Self-Sufficiency Analysis:**

‚úÖ **Strengths:**
- Complete extraction utilities with full code (lines 1209-1684)
- AI chunking logic fully specified (lines 1364-1537)
- Clear extraction limits (lines 1516-1535): 15/5/10/5 for each chunk type
- Comprehensive error handling examples

‚úÖ **Notable Strength - Prompt Engineering:**
- Lines 1422-1482 contain a complete, sophisticated AI prompt for chunk extraction
- This is excellent - shows the agent exactly how to structure prompts for Claude

‚ö†Ô∏è **Weaknesses:**
1. **Chunk Type Definitions** (lines 1436-1451)
   - Defines the 4 chunk types in the AI prompt but doesn't explain WHY these specific types
   - Agent might not understand the pedagogical reasoning

2. **Missing Context on Existing Dashboard** (lines 1736-1744)
   - Says "Modify DocumentSelectorServer.tsx" but doesn't explain current state
   - No visual or structural context for where button should appear

**Recommended Changes:**

```markdown
Add to line 1203 (before "YOUR TASK:"):

**CHUNK TYPE STRATEGY:**
The 4 chunk types serve specific LoRA training purposes:
- **Chapter_Sequential**: Long-form structural content for context understanding
- **Instructional_Unit**: Step-by-step procedures for task completion training
- **CER**: Claim-Evidence-Reasoning for analytical thinking patterns
- **Example_Scenario**: Case studies and examples for style mimicry

Extraction limits (15/5/10/5) balance comprehensive coverage with processing cost.

---
```

**Risk Level:** üü¢ LOW - Highly self-sufficient, minor context enhancement recommended

---

### BUILD PROMPT #3: AI Dimension Generation (Lines 1762-2097)

**Prompt Characteristics:**
- **Length:** 336 lines
- **Complexity:** High
- **External Dependencies:** Minimal

**Self-Sufficiency Analysis:**

‚úÖ **Strengths:**
- Complete dimension generator implementation (lines 1772-2032)
- Clear batch processing strategy (lines 1831-1846): 3 chunks at a time
- Cost calculation logic included (lines 1976-1979)
- Comprehensive mapping of AI responses to dimension fields (lines 1986-2031)

‚úÖ **Notable Strength - Prompt Template Logic:**
- Lines 1908-1931 show how to execute prompt templates sequentially
- Lines 1936-1982 demonstrate robust AI interaction with error handling

‚ö†Ô∏è **Weaknesses:**
1. **Prompt Template Dependency** (lines 1802-1813, 1908)
   - Assumes prompt templates exist in database (they do, from human setup)
   - But doesn't explain what happens if a template is missing or inactive
   - No fallback strategy specified

2. **Confidence Score Generation** (lines 1901-1904)
   - Sets `generation_confidence_precision` and `generation_confidence_accuracy` to null
   - These are CRITICAL for Build Prompt #4's "Things We Know / Need to Know" display
   - No guidance on how these should actually be calculated

**Critical Issue Identified:**

Build Prompt #4 depends on confidence scores to categorize dimensions:
```typescript
// From Build Prompt #4, lines 2240-2242, 2267-2269
getHighConfidenceDimensions(chunk): DimensionWithConfidence[] {
  // Get dimensions with confidence >= 75%
}
getLowConfidenceDimensions(chunk): DimensionWithConfidence[] {
  // Get dimensions with confidence < 75%
}
```

But Build Prompt #3 never generates these confidence scores! This is a **CRITICAL GAP**.

**Recommended Changes:**

```markdown
Add to lines 1901-1904 (replace null assignments):

// Meta-dimensions - CRITICAL: These confidence scores are used by the dashboard
// to categorize dimensions into "Things We Know" (>=75%) vs "Things We Need to Know" (<75%)
generation_confidence_precision: this.calculateConfidence(dimensions, 'precision'),
generation_confidence_accuracy: this.calculateConfidence(dimensions, 'accuracy'),

// Add after line 2031:

/**
 * Calculate confidence score based on response completeness
 */
private calculateConfidence(dimensions: Partial<ChunkDimensions>, type: 'precision' | 'accuracy'): number {
  // Count non-null, non-empty fields
  const fields = Object.values(dimensions).filter(v => 
    v !== null && v !== undefined && v !== '' && 
    !(Array.isArray(v) && v.length === 0)
  );
  
  const totalFields = Object.keys(dimensions).length;
  const filledFields = fields.length;
  
  // Precision: percentage of fields filled
  // Accuracy: subjective score (could be enhanced with AI self-assessment)
  const baseScore = (filledFields / totalFields) * 10;
  
  // Add randomness for testing (remove in production)
  const variance = type === 'precision' ? 0 : Math.random() * 2 - 1;
  
  return Math.min(10, Math.max(1, Math.round(baseScore + variance)));
}
```

**Risk Level:** üî¥ CRITICAL - Missing confidence calculation breaks Build Prompt #4

---

### BUILD PROMPT #4: Chunk Dashboard & Spreadsheet Interface (Lines 2100-2523)

**Prompt Characteristics:**
- **Length:** 424 lines
- **Complexity:** Very High
- **External Dependencies:** **CRITICAL - EXTENSIVE**

**Self-Sufficiency Analysis:**

‚ùå **Critical External Dependencies:**

1. **Dashboard Wireframe Design Reference** (Referenced at lines 2103-2111)
   ```
   Line 2103: "CRITICAL: This prompt REQUIRES you to follow the Dashboard Wireframe Design Reference section above."
   Line 2106: "VISUAL TARGET: Refer to Figure 1 in Dashboard Wireframe Design Reference section above"
   ```
   
   **Problem:** This section (lines 59-346, 288 lines) is NOT included in the prompt.
   
   **What's Missing:**
   - Visual screenshot (lines 70-87)
   - Three-section card structure (lines 124-198)
   - Color coding system (lines 200-225)
   - Icon mappings (lines 285-301)
   - Design principles (lines 303-327)
   
   **Impact:** Without this, the agent will:
   - Not know about the three-section layout pattern
   - Not use correct color scheme
   - Not implement progressive disclosure correctly
   - Create a different UI than intended

2. **Helper Function Implementations Missing** (lines 2340-2350)
   ```typescript
   function getHighConfidenceDimensions(chunk: any): DimensionWithConfidence[] {
     // Get dimensions with confidence >= 75%
     // Sort by confidence descending
     // Return top items
   }
   
   function getLowConfidenceDimensions(chunk: any): DimensionWithConfidence[] {
     // Get dimensions with confidence < 75%
     // Sort by confidence ascending
     // Return bottom items
   }
   ```
   
   **Problem:** These are stub implementations with comments, not actual code.
   
   **Impact:** Agent must infer the implementation, may get it wrong.

‚úÖ **Strengths:**
- Comprehensive component structure shown (lines 2122-2327)
- Clear color coding function provided (lines 2330-2338)
- Spreadsheet component fully specified (lines 2366-2508)

**Detailed Dependency Analysis:**

| Referenced Content | Lines in Reference Section | Lines in Prompt | Status |
|-------------------|---------------------------|-----------------|---------|
| Three-section card layout | 124-198 | 2210-2294 | ‚ö†Ô∏è PARTIAL - Structure shown but design rationale missing |
| Color coding system | 200-225 | 2330-2338 | ‚úÖ INCLUDED - Chunk type colors provided |
| Icon usage | 285-301 | Various | ‚úÖ INCLUDED - Icons used correctly |
| Progressive disclosure | 310-312 | 2271-2279 | ‚úÖ INCLUDED - "Detail View" button present |
| Confidence thresholds | 305-308 | 2241, 2268 | ‚ö†Ô∏è IMPLIED - 75% threshold used but not explained |
| Analysis summary layout | 257-282 | 2300-2324 | ‚úÖ INCLUDED - 4-column stats matched |

**The Most Critical Missing Piece:**

The prompt shows WHAT to build (line-by-line component code) but not WHY. The design reference explains:

```markdown
From lines 303-327 (Design Principles):

1. Color-Coded Confidence:
   - Green = High confidence (Things We Know)
   - Orange = Low confidence (Things We Need to Know)
   - Gray/White = Neutral metadata

2. Progressive Disclosure:
   - Overview shows 3 top items in each section
   - "Detail View" button expands to full spreadsheet

3. Visual Hierarchy:
   - Chunk metadata (functional data) at top
   - Positive findings (what AI knows) in middle
   - Knowledge gaps (what's missing) at bottom
```

This context is ESSENTIAL for the agent to make correct implementation decisions when the code isn't 100% explicit.

**Recommended Changes:**

**Option 1: Embed Full Design Reference (Recommended)**
```markdown
Insert after line 2111, before "YOUR TASK:":

---

### DESIGN REFERENCE: UI Patterns You MUST Follow

**Visual Target Screenshot:**
![Chunk Dashboard](https://p191.p3.n0.cdn.zight.com/items/7Kur9xl7/f61f84fd-2b70-407c-ac6a-cd8cbc85116f.png)

[Include lines 78-327 from Dashboard Wireframe Design Reference section]

This creates a self-contained prompt with all necessary design context.

---
```

**Option 2: Create Condensed Design Primer**
```markdown
Insert after line 2111:

### CRITICAL DESIGN PATTERNS

**Three-Section Card Layout (MUST IMPLEMENT EXACTLY):**
Every chunk card has three sections with specific backgrounds:

1. **Chunk Metadata** (neutral/white background: `bg-white/30`)
   - Mechanical data: chars, tokens, pages
   - Grid layout: `grid grid-cols-2 md:grid-cols-4`

2. **Things We Know** (green background: `bg-green-50 border-green-200`)
   - High confidence dimensions (>=75%)
   - Show top 3 findings
   - Each with confidence percentage badge
   - Icon: `<CheckCircle className="h-3 w-3" />`

3. **Things We Need to Know** (orange background: `bg-orange-50 border-orange-200`)
   - Low confidence dimensions (<75%)
   - Show top 3 gaps
   - "Detail View" button to full spreadsheet
   - Icon: `<AlertCircle className="h-3 w-3" />`

**Color Coding System:**
- Chapter_Sequential: `border-blue-200 bg-blue-50`
- Instructional_Unit: `border-purple-200 bg-purple-50`
- CER: `border-orange-200 bg-orange-50`
- Example_Scenario: `border-yellow-200 bg-yellow-50`

**Typography Scale:**
- Section headings: `text-sm font-medium`
- Body text: `text-xs`
- Generous padding: `p-3` for sections, `p-4` for summary cards

**Progressive Disclosure:**
- Show 3 items per section in overview
- "Detail View" button navigates to full spreadsheet
- Use `slice(0, 3)` to limit displayed items

---
```

**Risk Level:** üî¥ CRITICAL - Cannot execute successfully without design reference

---

### BUILD PROMPT #5: Run Management & Polish (Lines 2527-2562)

**Prompt Characteristics:**
- **Length:** 36 lines
- **Complexity:** Low (intentionally high-level)
- **External Dependencies:** Minimal

**Self-Sufficiency Analysis:**

‚ö†Ô∏è **Intentionally Brief:**
This prompt is deliberately concise, providing high-level goals rather than detailed implementations. This is appropriate for a "polish" phase where the agent has context from previous prompts.

**Content:**
- Part A: Run Comparison (lines 2533-2539)
- Part B: Regeneration (lines 2541-2548)
- Part C: Polish & Testing (lines 2550-2555)

**Weaknesses:**
1. **No Code Examples** - Unlike other prompts, this provides no implementation guidance
2. **Vague Requirements** - "Add loading states everywhere" is not specific
3. **Dependencies on Previous Work** - Assumes Prompts #1-4 were completed correctly

**Risk Analysis:**
- **üü° MODERATE RISK** if previous prompts had issues
- **üü¢ LOW RISK** if previous prompts were executed successfully

**Recommendation:** 
ADD MORE SPECIFIC GUIDANCE for each part:

```markdown
Replace lines 2533-2555 with:

### Part A: Run Comparison Interface

Create `src/components/chunks/RunComparison.tsx`:

**Requirements:**
- Accept multiple run_ids as input (2-5 runs)
- Display side-by-side table with one run per column
- Highlight differences in cell background colors:
  - Green: Value improved vs previous run
  - Red: Value degraded vs previous run
  - Yellow: Value changed but unclear if better
- Add "Export Comparison" button (CSV format)
- Include diff statistics at top (X fields changed, Y improved, Z degraded)

**Key Functions:**
```typescript
function compareRuns(runs: ChunkDimensions[]): ComparisonResult {
  // Compare dimension values across runs
  // Return differences and statistics
}

function getDifferenceColor(oldValue: any, newValue: any, field: string): string {
  // Determine if change is positive, negative, or neutral
  // Return color class
}
```

### Part B: Regeneration Capability

Add to `src/app/chunks/[documentId]/page.tsx`:

**Requirements:**
- Add "Regenerate Dimensions" button to each chunk card
- On click, show modal with options:
  - Regenerate selected chunks only
  - Regenerate all chunks in document
  - Select which prompt templates to use
- Create new run_id for regeneration
- Preserve all historical runs (never delete)
- Show progress indicator during regeneration
- Refresh dashboard when complete

**API Endpoint:**
Create `src/app/api/chunks/regenerate/route.ts`
- Accept: documentId, chunkIds[], templateIds[]
- Call: DimensionGenerator.generateDimensionsForDocument()
- Return: new run_id

### Part C: Polish & Testing Checklist

**Loading States to Add:**
- [ ] Document list: Skeleton loader while fetching
- [ ] Chunk extraction: Progress bar with percentage
- [ ] Dimension generation: Animated spinner with "Analyzing chunk X of Y"
- [ ] Spreadsheet: Table skeleton while loading data
- [ ] Run comparison: Loading overlay with "Comparing runs..."

**Error Boundaries to Add:**
- [ ] Wrap `/chunks/[documentId]` page with ErrorBoundary
- [ ] Wrap ChunkSpreadsheet component with ErrorBoundary
- [ ] Wrap RunComparison component with ErrorBoundary
- [ ] Add fallback UI for each boundary with "Try Again" button

**Toast Notifications to Add:**
- [ ] Chunk extraction started: "Extracting chunks..."
- [ ] Chunk extraction complete: "Extracted X chunks successfully"
- [ ] Dimension generation started: "Generating dimensions..."
- [ ] Dimension generation complete: "Generated X dimensions in Y seconds"
- [ ] Regeneration complete: "Regeneration complete! View new run."
- [ ] Export success: "Data exported to downloads folder"
- [ ] Errors: Show error message with retry option

**End-to-End Test Script:**
1. Start with categorized document
2. Click "Chunks" button
3. Verify chunk extraction progress updates
4. Verify chunks appear in database
5. Verify dimension generation starts automatically
6. Verify dimensions saved with confidence scores
7. Verify dashboard displays three-section layout
8. Click "Detail View" and verify spreadsheet opens
9. Test sorting by clicking column headers
10. Test filtering with search input
11. Test preset view buttons (Quality, Cost, Content, Risk)
12. Test run comparison with 2 runs
13. Test regeneration for single chunk
14. Test export functionality
```

**Risk Level:** üü° MODERATE - Needs more specific guidance

---

## CRITICAL GAPS SUMMARY

### Gap #1: Missing Confidence Calculation (BLOCKS BUILD PROMPT #4)

**Location:** Build Prompt #3, lines 1901-1904

**Problem:**
```typescript
// Current code sets these to null:
generation_confidence_precision: null,
generation_confidence_accuracy: null,
```

**Impact:**
- Build Prompt #4 requires these scores to separate "Things We Know" (>=75%) from "Things We Need to Know" (<75%)
- Without scores, ALL dimensions appear in "Things We Need to Know" or agent must invent scoring logic
- UI will not function as designed

**Solution Priority:** üî¥ CRITICAL - MUST FIX BEFORE BUILD PROMPT #4

---

### Gap #2: Dashboard Design Reference Not In Prompt (BLOCKS BUILD PROMPT #4)

**Location:** Build Prompt #4, lines 2103-2111

**Problem:**
- Prompt says "REQUIRES you to follow the Dashboard Wireframe Design Reference section above"
- That section (lines 59-346) is NOT included in the prompt
- Agent receiving only Build Prompt #4 will not have access to design specifications

**Impact:**
- Agent will implement UI without knowing correct patterns
- Three-section layout may be wrong or missing
- Color scheme will be different
- Progressive disclosure may not work correctly

**Solution Priority:** üî¥ CRITICAL - MUST FIX BEFORE BUILD PROMPT #4

---

### Gap #3: Helper Functions Are Stubs (BLOCKS BUILD PROMPT #4)

**Location:** Build Prompt #4, lines 2340-2350

**Problem:**
```typescript
function getHighConfidenceDimensions(chunk: any): DimensionWithConfidence[] {
  // Get dimensions with confidence >= 75%
  // Sort by confidence descending
  // Return top items
}
```

**Impact:**
- Agent must implement these functions from comments
- May implement incorrectly (wrong field names, wrong logic)
- Type `DimensionWithConfidence` is not defined

**Solution Priority:** üü° MODERATE - Provide full implementations

---

### Gap #4: Vague Polish Requirements (MAY DELAY BUILD PROMPT #5)

**Location:** Build Prompt #5, entire prompt

**Problem:**
- Instructions like "Add loading states everywhere" are not specific
- No code examples unlike other prompts
- Relies heavily on agent interpretation

**Impact:**
- Agent may skip important polish items
- Inconsistent implementation
- May need multiple clarification rounds

**Solution Priority:** üü¢ LOW-MODERATE - Add specific checklist

---

### Gap #5: Missing Module Context in Prompt #1

**Location:** Build Prompt #1, line 786

**Problem:**
- Jumps straight into "You are building the foundation"
- Doesn't explain what the module does or why

**Impact:**
- Agent lacks strategic context
- May make suboptimal architectural decisions
- Doesn't understand how pieces fit together

**Solution Priority:** üü¢ LOW - Nice to have, not blocking

---

## RECOMMENDATIONS

### Immediate Actions Required (Before Giving Prompts to Coding Agent)

#### Action 1: Fix Confidence Calculation in Build Prompt #3 ‚ö° CRITICAL

**File:** `c-alpha-build-spec_v3.2.md`  
**Lines to Modify:** 1901-1904, add new method after 2031

**Change 1 - Replace lines 1901-1904:**
```typescript
// OLD:
generation_confidence_precision: null,
generation_confidence_accuracy: null,

// NEW:
generation_confidence_precision: this.calculatePrecisionScore(dimensions),
generation_confidence_accuracy: this.calculateAccuracyScore(dimensions),
```

**Change 2 - Add after line 2031:**
```typescript
  /**
   * Calculate precision score (1-10) based on response completeness
   * Used by dashboard to determine "Things We Know" (>=8) vs "Things We Need to Know" (<8)
   */
  private calculatePrecisionScore(dimensions: Partial<ChunkDimensions>): number {
    // Count non-null, non-empty dimensional fields
    const dimensionFields = [
      dimensions.chunk_summary_1s,
      dimensions.key_terms,
      dimensions.audience,
      dimensions.intent,
      dimensions.tone_voice_tags,
      dimensions.brand_persona_tags,
      dimensions.domain_tags,
      dimensions.task_name,
      dimensions.claim,
      dimensions.scenario_type,
      // Add other key dimension fields
    ].filter(Boolean);

    const totalExpected = 10; // Adjust based on chunk type
    const filled = dimensionFields.length;
    
    // Score 1-10 based on completeness
    return Math.round((filled / totalExpected) * 10);
  }

  /**
   * Calculate accuracy score (1-10) - subjective quality assessment
   * In MVP, use precision score with slight variance for testing
   */
  private calculateAccuracyScore(dimensions: Partial<ChunkDimensions>): number {
    const precisionScore = this.calculatePrecisionScore(dimensions);
    
    // Add slight variance for realistic testing
    // In production, this could use AI self-assessment
    const variance = Math.floor(Math.random() * 3) - 1; // -1, 0, or 1
    
    return Math.max(1, Math.min(10, precisionScore + variance));
  }
```

**Rationale:**
- Dashboard requires confidence scores to be numeric (1-10 scale)
- Score >= 8 (80%) appears in "Things We Know" (green section)
- Score < 8 appears in "Things We Need to Know" (orange section)
- This provides the data structure Build Prompt #4 expects

---

#### Action 2: Embed Design Reference in Build Prompt #4 ‚ö° CRITICAL

**File:** `c-alpha-build-spec_v3.2.md`  
**Insert Location:** After line 2111, before "YOUR TASK:"

**Insert This Section:**

```markdown
---

## CRITICAL: DASHBOARD DESIGN PATTERNS YOU MUST IMPLEMENT

**Reference Screenshot:**
![Target Dashboard Design](https://p191.p3.n0.cdn.zight.com/items/7Kur9xl7/f61f84fd-2b70-407c-ac6a-cd8cbc85116f.png)

### Three-Section Card Layout (MANDATORY STRUCTURE)

Every chunk card MUST have this exact three-section structure:

#### Section 1: Chunk Metadata (Neutral Background)
```typescript
<div className="mb-4 p-3 bg-white/30 rounded border">
  <h5 className="text-sm font-medium mb-2 flex items-center gap-2">
    <Hash className="h-3 w-3" />
    Chunk Metadata
  </h5>
  <div className="grid grid-cols-2 md:grid-cols-4 gap-3 text-xs">
    {/* Mechanical data: chars, tokens, page numbers */}
  </div>
</div>
```

**Purpose:** Display mechanical, objective chunk data  
**Color:** Neutral/white (`bg-white/30`)  
**Content:** Character count, token count, page numbers, chunk type

#### Section 2: Things We Know (Green Background)
```typescript
<div className="mb-4 p-3 bg-green-50 rounded border border-green-200">
  <h5 className="text-sm font-medium mb-2 flex items-center gap-2 text-green-800">
    <CheckCircle className="h-3 w-3" />
    Things We Know ({highConfidenceCount})
  </h5>
  {/* Show dimensions where generation_confidence_accuracy >= 8 */}
  {/* Display top 3 highest confidence findings */}
  {/* Each finding shows: dimension name, confidence %, value */}
</div>
```

**Purpose:** Display high-confidence AI-generated dimensions  
**Color:** Green (`bg-green-50`, `border-green-200`)  
**Content:** Dimensions with `generation_confidence_accuracy >= 8`  
**Display Logic:** Show top 3 by confidence, sorted descending

#### Section 3: Things We Need to Know (Orange Background)
```typescript
<div className="p-3 bg-orange-50 rounded border border-orange-200">
  <div className="flex items-center justify-between mb-2">
    <h5 className="text-sm font-medium flex items-center gap-2 text-orange-800">
      <AlertCircle className="h-3 w-3" />
      Things We Need to Know ({lowConfidenceCount})
    </h5>
    <Button variant="outline" size="sm" className="text-xs h-6 px-2 border-orange-300 text-orange-700 hover:bg-orange-100">
      <ExternalLink className="h-3 w-3 mr-1" />
      Detail View
    </Button>
  </div>
  {/* Show dimensions where generation_confidence_accuracy < 8 */}
  {/* Display top 3 lowest confidence dimensions */}
</div>
```

**Purpose:** Display low-confidence dimensions needing review  
**Color:** Orange (`bg-orange-50`, `border-orange-200`)  
**Content:** Dimensions with `generation_confidence_accuracy < 8`  
**Display Logic:** Show top 3 by confidence, sorted ascending  
**Action:** "Detail View" button ‚Üí Navigate to full spreadsheet

### Color Coding System

**Chunk Type Border/Background Colors:**
```typescript
function getChunkTypeColor(type: string): string {
  const colors = {
    'Chapter_Sequential': 'border-blue-200 bg-blue-50',
    'Instructional_Unit': 'border-purple-200 bg-purple-50',
    'CER': 'border-orange-200 bg-orange-50',
    'Example_Scenario': 'border-yellow-200 bg-yellow-50',
  };
  return colors[type] || 'border-gray-200 bg-gray-50';
}
```

**Confidence Indicator Colors:**
- High Confidence (>=8): Green text (`text-green-600`), green background (`bg-green-100`)
- Low Confidence (<8): Orange text (`text-orange-600`), orange background (`bg-orange-100`)
- Neutral Data: Gray text (`text-muted-foreground`)

### Icons from lucide-react

Required imports:
```typescript
import { 
  FileText,      // Document/chunk icon
  CheckCircle,   // High confidence indicator
  AlertCircle,   // Low confidence indicator  
  Hash,          // Metadata section icon
  ExternalLink,  // Detail view link
  ArrowRight,    // List item bullets
  Clock,         // Duration/timing
  Brain,         // AI-related
} from 'lucide-react';
```

### Typography Scale

- **Main heading:** `text-xl font-medium`
- **Card title:** `font-medium`
- **Section headings:** `text-sm font-medium`
- **Body text:** `text-xs`
- **Muted text:** `text-xs text-muted-foreground`

### Spacing and Padding

- **Container:** `container mx-auto px-4 py-6`
- **Section spacing:** `space-y-6` for main sections, `space-y-4` for chunk cards
- **Card content:** `pt-0` on CardContent to remove default top padding
- **Section boxes:** `p-3` for inner sections, `p-4` for summary cards
- **Grid gaps:** `gap-3` for metadata grid, `gap-4` for summary stats

### Progressive Disclosure Pattern

**Overview (Chunk Dashboard):**
- Show 3 items in "Things We Know"
- Show 3 items in "Things We Need to Know"
- Use `.slice(0, 3)` to limit display

**Detail View (Spreadsheet):**
- Show ALL dimensions in table format
- Triggered by "Detail View" button
- Navigate to `/chunks/[documentId]/spreadsheet/[chunkId]`

### Analysis Summary (Bottom of Page)

4-column stat cards:
```typescript
<div className="grid md:grid-cols-4 gap-4">
  <div className="text-center p-4 bg-blue-50 rounded">
    <div className="text-2xl font-medium text-blue-600">{totalChunks}</div>
    <div className="text-sm text-blue-800">Total Chunks</div>
  </div>
  {/* Repeat for: Analyzed (green), Dimensions (orange), Cost (purple) */}
</div>
```

**Colors:** Blue ‚Üí Green ‚Üí Orange ‚Üí Purple

---

**IMPLEMENTATION CHECKLIST:**
- [ ] Three-section layout in every chunk card
- [ ] Confidence-based categorization (>=8 vs <8)
- [ ] Correct color scheme (green=known, orange=gaps)
- [ ] Progressive disclosure (3 items ‚Üí Detail View)
- [ ] Icons from lucide-react
- [ ] Typography scale consistent
- [ ] Analysis summary with 4 colored cards

---
```

**Rationale:**
- Makes Build Prompt #4 completely self-contained
- Agent has all design information needed to implement correctly
- Removes dependency on external section
- Clear, actionable specifications with code examples

---

#### Action 3: Implement Missing Helper Functions in Build Prompt #4

**File:** `c-alpha-build-spec_v3.2.md`  
**Lines to Replace:** 2340-2350

**Replace with Full Implementations:**

```typescript
// Replace lines 2340-2350 with:

interface DimensionWithConfidence {
  fieldName: string;
  value: any;
  confidence: number; // 1-10 scale
}

function getHighConfidenceDimensions(chunk: any): DimensionWithConfidence[] {
  // Get the latest dimension data for this chunk
  if (!chunk.dimensions || chunk.dimensions.length === 0) return [];
  
  const latestDim = chunk.dimensions[0]; // Assume sorted by generated_at DESC
  
  // Extract all dimensional fields with confidence scores
  const dimensionsWithScores: DimensionWithConfidence[] = [];
  
  // Add fields based on type - only include populated fields
  const fieldMappings = {
    chunk_summary_1s: latestDim.chunk_summary_1s,
    key_terms: latestDim.key_terms,
    audience: latestDim.audience,
    intent: latestDim.intent,
    tone_voice_tags: latestDim.tone_voice_tags,
    brand_persona_tags: latestDim.brand_persona_tags,
    domain_tags: latestDim.domain_tags,
    task_name: latestDim.task_name,
    preconditions: latestDim.preconditions,
    expected_output: latestDim.expected_output,
    claim: latestDim.claim,
    evidence_snippets: latestDim.evidence_snippets,
    reasoning_sketch: latestDim.reasoning_sketch,
    scenario_type: latestDim.scenario_type,
    problem_context: latestDim.problem_context,
    solution_action: latestDim.solution_action,
  };
  
  Object.entries(fieldMappings).forEach(([fieldName, value]) => {
    if (value !== null && value !== undefined && value !== '') {
      // Use accuracy score as primary confidence indicator
      const confidence = latestDim.generation_confidence_accuracy || 5;
      
      if (confidence >= 8) { // High confidence threshold
        dimensionsWithScores.push({ fieldName, value, confidence });
      }
    }
  });
  
  // Sort by confidence descending, return all (UI will slice to 3)
  return dimensionsWithScores.sort((a, b) => b.confidence - a.confidence);
}

function getLowConfidenceDimensions(chunk: any): DimensionWithConfidence[] {
  // Get the latest dimension data for this chunk
  if (!chunk.dimensions || chunk.dimensions.length === 0) return [];
  
  const latestDim = chunk.dimensions[0];
  
  const dimensionsWithScores: DimensionWithConfidence[] = [];
  
  // Same field mappings as above
  const fieldMappings = {
    chunk_summary_1s: latestDim.chunk_summary_1s,
    key_terms: latestDim.key_terms,
    audience: latestDim.audience,
    intent: latestDim.intent,
    tone_voice_tags: latestDim.tone_voice_tags,
    brand_persona_tags: latestDim.brand_persona_tags,
    domain_tags: latestDim.domain_tags,
    task_name: latestDim.task_name,
    preconditions: latestDim.preconditions,
    expected_output: latestDim.expected_output,
    claim: latestDim.claim,
    evidence_snippets: latestDim.evidence_snippets,
    reasoning_sketch: latestDim.reasoning_sketch,
    scenario_type: latestDim.scenario_type,
    problem_context: latestDim.problem_context,
    solution_action: latestDim.solution_action,
  };
  
  Object.entries(fieldMappings).forEach(([fieldName, value]) => {
    const confidence = latestDim.generation_confidence_accuracy || 5;
    
    // Include fields that are null/empty OR have low confidence
    if (value === null || value === undefined || value === '' || confidence < 8) {
      dimensionsWithScores.push({ 
        fieldName, 
        value: value || '(Not generated)', 
        confidence 
      });
    }
  });
  
  // Sort by confidence ascending (lowest first)
  return dimensionsWithScores.sort((a, b) => a.confidence - b.confidence);
}

function truncate(text: string, maxLength: number): string {
  if (!text || text.length <= maxLength) return text;
  return text.substring(0, maxLength) + '...';
}

function hasDimensions(chunk: any): boolean {
  return chunk.dimensions && chunk.dimensions.length > 0;
}
```

---

### Strategic Recommendations

#### Recommendation A: Adopt Hybrid Approach (Recommended) ‚úÖ

**Strategy:**
1. **Embed critical content** directly into prompts (Actions 1-3 above)
2. **Keep full spec available** as reference document for coding agent
3. **Add explicit cross-references** with line numbers in embedded content
4. **Create index** at start of spec showing what's where

**Advantages:**
- ‚úÖ Prompts become self-contained and executable
- ‚úÖ Agent can still reference full spec for context
- ‚úÖ Reduces risk of missing critical information
- ‚úÖ Maintains specification as single source of truth

**Disadvantages:**
- ‚ö†Ô∏è Increases prompt length (~150-200 lines added to Prompt #4)
- ‚ö†Ô∏è Some duplication between embedded content and reference sections

**Estimated Effort:** 2-3 hours

---

#### Recommendation B: Create Prompt Packages

**Strategy:**
Instead of giving agents bare prompts, create "prompt packages" that include:
1. The build prompt itself
2. Relevant excerpts from reference sections
3. Links to full specification for context

**Example Package Structure:**
```
BUILD_PROMPT_4_PACKAGE/
‚îú‚îÄ‚îÄ main-prompt.md (Build Prompt #4)
‚îú‚îÄ‚îÄ design-reference.md (Lines 59-346 extracted)
‚îú‚îÄ‚îÄ dependencies.md (List of expected completions from Prompts 1-3)
‚îî‚îÄ‚îÄ full-spec-link.md (Link to c-alpha-build-spec_v3.2.md)
```

**Advantages:**
- ‚úÖ Maximum flexibility for agent
- ‚úÖ No duplication in main spec
- ‚úÖ Can provide different package variants

**Disadvantages:**
- ‚ö†Ô∏è More complex to maintain
- ‚ö†Ô∏è Agent must know to read multiple files
- ‚ö†Ô∏è Risk of package files going out of sync with main spec

**Estimated Effort:** 4-6 hours

---

#### Recommendation C: Sequential Context Building

**Strategy:**
Give coding agent the FULL specification at the start, then give each build prompt as an addendum that says "Now execute Build Prompt #X from the specification you've loaded."

**Advantages:**
- ‚úÖ Agent has full context always
- ‚úÖ No changes needed to specification structure
- ‚úÖ Simple execution model

**Disadvantages:**
- ‚ö†Ô∏è Uses more tokens per interaction
- ‚ö†Ô∏è Agent may get confused about what to focus on
- ‚ö†Ô∏è Requires discipline to not jump ahead to later prompts

**Estimated Effort:** 0 hours (no changes needed)

---

### Final Recommendation: **Hybrid Approach (Recommendation A)**

**Rationale:**
1. **Highest Success Probability:** Self-contained prompts reduce risk of missing information
2. **Reasonable Effort:** 2-3 hours to implement is acceptable for a 20-hour build
3. **Maintains Spec Integrity:** Full specification remains as master document
4. **Flexible Execution:** Works whether agent gets prompts individually or has full context

**Implementation Order:**
1. ‚úÖ Action 1: Fix confidence calculation (30 min)
2. ‚úÖ Action 2: Embed design reference in Prompt #4 (60 min)
3. ‚úÖ Action 3: Implement helper functions (30 min)
4. ‚úÖ Optional: Add module context to Prompt #1 (15 min)
5. ‚úÖ Optional: Expand Prompt #5 with specifics (30 min)

**Total Effort:** ~2.5 hours

---

## TESTING VALIDATION PLAN

After implementing recommended changes, validate each build prompt:

### Validation Test #1: Build Prompt #3 Confidence Generation
```
‚úÖ Check line ~1901-1904: confidence scores are calculated, not null
‚úÖ Check after line ~2031: helper methods exist
‚úÖ Verify scores are on 1-10 scale
‚úÖ Verify scores are stored in chunk_dimensions table
```

### Validation Test #2: Build Prompt #4 Design Reference
```
‚úÖ Check after line ~2111: design reference section embedded
‚úÖ Verify three-section layout is explained
‚úÖ Verify color coding system is present
‚úÖ Verify confidence threshold (>=8 vs <8) is explicit
‚úÖ Verify icons are listed
```

### Validation Test #3: Build Prompt #4 Helper Functions
```
‚úÖ Check lines ~2340-2350: full implementations exist
‚úÖ Verify DimensionWithConfidence type is defined
‚úÖ Verify getHighConfidenceDimensions logic is complete
‚úÖ Verify getLowConfidenceDimensions logic is complete
‚úÖ Verify hasDimensions helper exists
```

### Validation Test #4: Cross-Prompt Dependencies
```
‚úÖ Prompt #1 ‚Üí Prompt #2: chunk services available
‚úÖ Prompt #2 ‚Üí Prompt #3: chunk extraction complete
‚úÖ Prompt #3 ‚Üí Prompt #4: dimensions with confidence scores
‚úÖ Prompt #4 ‚Üí Prompt #5: dashboard and spreadsheet complete
```

---

## CONCLUSION

### Current State
The specification is **75% ready** for coding agent execution:
- ‚úÖ Build Prompts #1, #2: Excellent, minimal issues
- ‚ö†Ô∏è Build Prompt #3: Missing confidence calculation (CRITICAL)
- ‚ùå Build Prompt #4: Missing design reference (CRITICAL)
- ‚ö†Ô∏è Build Prompt #5: Needs more specificity (MODERATE)

### Required Actions
**MUST FIX before coding agent receives prompts:**
1. Add confidence score calculation to Build Prompt #3
2. Embed design reference into Build Prompt #4
3. Implement helper functions in Build Prompt #4

**SHOULD FIX for better results:**
4. Add module context to Build Prompt #1
5. Expand Build Prompt #5 with specific requirements

### Post-Fix State
After implementing recommended changes:
- ‚úÖ All 5 build prompts will be self-contained
- ‚úÖ No critical external dependencies
- ‚úÖ Clear success criteria for each phase
- ‚úÖ Ready for sequential execution by coding agent

### Estimated Timeline
- **Changes Implementation:** 2.5 hours
- **Validation Testing:** 1 hour  
- **Total to Ready State:** 3.5 hours

---

**END OF AUDIT REPORT**

*This audit was conducted on October 5, 2025, for specification version 3.2. If the specification is updated, re-audit affected sections.*

